Checking serif vs sans:

Classified 33/52 correctly (63.46%)
Average certainty for correct classification: 0.032 (min: 0.021)
Average certainty for incorrect classification: 0.025 (max: 0.029)
Incorrect classifications:
          Thought B was I (certainty: 0.024); alternatives were l, i, B
          Thought D was l (certainty: 0.025); alternatives were I, B, D
          Thought g was r (certainty: 0.023); alternatives were i, g, q
          Thought H was s (certainty: 0.027); alternatives were H, i, F
          Thought i was j (certainty: 0.026); alternatives were g, R, F
          Thought J was R (certainty: 0.026); alternatives were j, E, F
          Thought l was R (certainty: 0.024); alternatives were i, l, I
          Thought M was q (certainty: 0.024); alternatives were M, o, p
          Thought n was R (certainty: 0.027); alternatives were h, J, o
          Thought p was i (certainty: 0.024); alternatives were r, P, l
          Thought P was i (certainty: 0.025); alternatives were r, F, l
          Thought q was i (certainty: 0.025); alternatives were I, o, l
          Thought Q was o (certainty: 0.027); alternatives were O, Q, i
          Thought r was i (certainty: 0.023); alternatives were T, I, l
          Thought R was j (certainty: 0.029); alternatives were n, J, P
          Thought T was B (certainty: 0.026); alternatives were l, I, D
          Thought w was L (certainty: 0.023); alternatives were o, l, I
          Thought W was L (certainty: 0.024); alternatives were o, q, I
          Thought Y was r (certainty: 0.026); alternatives were Y, o, b

Results for sign1:

Classified 10/15 correctly (66.67%)
Average certainty for correct classification: 0.029 (min: 0.025)
Average certainty for incorrect classification: 0.028 (max: 0.032)
Incorrect classifications:
          Thought G was c (certainty: 0.032); alternatives were C, e, G
          Thought H was K (certainty: 0.025); alternatives were H, k, b
          Thought M was b (certainty: 0.030); alternatives were w, W, M
          Thought N was K (certainty: 0.028); alternatives were k, i, b
          Thought P was o (certainty: 0.026); alternatives were O, Q, i

Most results look fairly sane.  We can add second (encolsed) contour
checks which I think will improve some of these a bit.  We can still
check out some of the incorrect responses, but it seems like progress
is slowing down on this classifier, and it does a decent job.  Even
for those it doesn't classify correctly, the correct character is
often in the top four ranking.  This means we could match the word to
a dictionary and probably get good results.

Not sure if we still want to look into weighing correlation more than
error, etc.

Another observation is that when looking at plots of contour angles,
they often line up at the beginning, but start shifting out of phase
towards the end.  (Look into why cross-correlation lines the beginning
up more than the end.)  This can be true of letters with different
thickness, or with serifs, etc., when the permiter of one letter is
longer than the other.  An idea to mitigate this is to split one
contour angle vector into sections (say 10), and then doing a
correlation on each with the other letter contour.  The mean x values
for each segment should at least be increasing, although we can
tolerate some overlap or gaps.  Then average the correlations and
errors.

Might be time to move on to a second classifier soon.  I'm thinking
just doing template matching.  We also need to start working on words.
The clustering approach worked promisingly before.

We may want to design some classifiers specifically for
differentiating between specific common letters.  E.g., if we think
something is a c, run simple classifiers to separate it from e and G.
These could be as simple as looking for pixels in specific areas.  It
would be cool if we had a learning algorithm that figured out the best
points to check for us.

We could also use the alternatives themselves to classify.  E.g., if
we see that P often matches O and Q, then if we see those letters high
in the rankings, it lends weight to the correct choice being a P.  Of
course, we need to avoid classifying O or Q as P just because they are
similar, but it basically gives us a clustering algorithm from which
we may be able to detect drastic misclassifications.  E.g., if we the
top rankings aren't in a known cluster, it indicates the guess is a
bad one.
